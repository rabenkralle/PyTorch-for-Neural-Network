{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch import optim\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "# device = torch.device(\"cpu\")\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"nturgb+d_skeletons/\"\n",
    "broken_files_path = \"NTU_RGBD120_samples_with_missing_skeletons.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_subjects = list(range(0, 28)) #количество людей выполняющих действия\n",
    "training_classes = sorted([8, 10, 22, 23, 27, 21, 55, 2, 7]) #классы которые будем использовать для обучения, полный список прдставлен тут https://github.com/shahroudy/NTURGB-D\n",
    "LABELS = {x: training_classes[x] for x in range(len(training_classes))}\n",
    "training_cameras = [1, 2, 3] \n",
    "\n",
    "# max_body_true = 1\n",
    "# max_body_kinect = 1\n",
    "\n",
    "num_joint = 25\n",
    "max_frame = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Skeleton_Dataset(Dataset):\n",
    "    def __init__(self, data_path, broken_files_path=None, training_classes=None,\n",
    "                 num_joint = 25, max_frame = 300, transform=None):\n",
    "        \n",
    "        \n",
    "        def read_data(data_path, broken_files_path):\n",
    "            labels = []\n",
    "            files = []\n",
    "            action_classes = {}\n",
    "            counter = 0\n",
    "            files_counter = {}\n",
    "            with open(broken_files_path, 'r') as f:\n",
    "                broken_files = f.read().split(\"\\n\")\n",
    "\n",
    "            raw_files = os.listdir(data_path)\n",
    "            num_frames = 0\n",
    "\n",
    "            for filename in raw_files:\n",
    "                if filename not in broken_files:\n",
    "                    action_class = int(filename[filename.find('A') + 1:filename.find('A') + 4])\n",
    "                    subject_id = int(filename[filename.find('P') + 1:filename.find('P') + 4])\n",
    "                    camera_id = int(filename[filename.find('C') + 1:filename.find('C') + 4])\n",
    "                    if action_class in training_classes and camera_id in training_cameras: \n",
    "                        if action_class in action_classes:\n",
    "                            if files_counter[action_class] < 120:\n",
    "                                files.append([filename,action_classes[action_class]])\n",
    "                                files_counter[action_class] = files_counter[action_class] + 1\n",
    "                        else:\n",
    "                            action_classes.update({action_class : counter})\n",
    "                            files_counter.update({action_class : 1})\n",
    "                            counter+=1\n",
    "                            files.append([filename,action_classes[action_class]])\n",
    "            print(\"action classes: \", action_classes)\n",
    "            print(\"action files: \", files_counter)\n",
    "\n",
    "            return files, action_classes\n",
    "        \n",
    "        \n",
    "        def read_skeleton_filter(file):\n",
    "            with open(file, 'r') as f:\n",
    "                skeleton_sequence = {}\n",
    "                skeleton_sequence['numFrame'] = int(f.readline())\n",
    "                skeleton_sequence['frameInfo'] = []\n",
    "                for t in range(skeleton_sequence['numFrame']):\n",
    "                    frame_info = {}\n",
    "                    frame_info['numBody'] = int(f.readline())\n",
    "                    frame_info['bodyInfo'] = []\n",
    "\n",
    "                    for m in range(frame_info['numBody']):\n",
    "                        body_info = {}\n",
    "                        body_info_key = [\n",
    "                            'bodyID', 'clipedEdges', 'handLeftConfidence',\n",
    "                            'handLeftState', 'handRightConfidence', 'handRightState',\n",
    "                            'isResticted', 'leanX', 'leanY', 'trackingState'\n",
    "                        ]\n",
    "                        body_info = {\n",
    "                            k: float(v)\n",
    "                            for k, v in zip(body_info_key, f.readline().split())\n",
    "                        }\n",
    "                        body_info['numJoint'] = int(f.readline())\n",
    "                        body_info['jointInfo'] = []\n",
    "                        for v in range(body_info['numJoint']):\n",
    "                            joint_info_key = [\n",
    "                                'x', 'y', 'z', 'depthX', 'depthY', 'colorX', 'colorY',\n",
    "                                'orientationW', 'orientationX', 'orientationY',\n",
    "                                'orientationZ', 'trackingState'\n",
    "                            ]\n",
    "                            joint_info = {\n",
    "                                k: float(v)\n",
    "                                for k, v in zip(joint_info_key, f.readline().split())\n",
    "                            }\n",
    "                            body_info['jointInfo'].append(joint_info)\n",
    "                        frame_info['bodyInfo'].append(body_info)\n",
    "                    skeleton_sequence['frameInfo'].append(frame_info)\n",
    "\n",
    "            return skeleton_sequence\n",
    "\n",
    "        def read_xyz(file, max_body=1, num_joint=25):\n",
    "            seq_info = read_skeleton_filter(file)\n",
    "            data = np.zeros((max_body, seq_info['numFrame'], num_joint, 3))\n",
    "            for n, f in enumerate(seq_info['frameInfo']):\n",
    "                for m, b in enumerate(f['bodyInfo']):\n",
    "                    for j, v in enumerate(b['jointInfo']):\n",
    "                        if m < max_body and j < num_joint:\n",
    "                            data[m, n, j, :] = [v['x'], v['y'], v['z']]\n",
    "\n",
    "                        else:\n",
    "                            pass\n",
    "\n",
    "            return data\n",
    "        \n",
    "        \n",
    "        def create_coords_blocks(test_file, chonk_len = 45):   \n",
    "            frame_counter = 0\n",
    "            new_labels = []\n",
    "            new_frames = []\n",
    "            blocks = []\n",
    "\n",
    "            test_frames = read_xyz(data_path + test_file[0])[0]\n",
    "            label = test_file[1]\n",
    "            slice_len = chonk_len * int(len(test_frames)/chonk_len)\n",
    "\n",
    "\n",
    "            for index in range(len(test_frames[:slice_len])):\n",
    "                frame_counter += 1\n",
    "                new_frames.append(test_frames[index].flatten())\n",
    "                if frame_counter == chonk_len:\n",
    "                    frame_counter = 0\n",
    "                    blocks.append(np.array(new_frames))\n",
    "                    new_labels = new_labels + [label]\n",
    "                    new_frames = []\n",
    "\n",
    "\n",
    "            return blocks, new_labels\n",
    "        \n",
    "        \n",
    "        ##### список файлов с лейблами на каждый файл \n",
    "        working_files_with_labels, action_classes = read_data(data_path, broken_files_path)\n",
    "        \n",
    "        data = []\n",
    "        labels = []\n",
    "        ##########################################################################\n",
    "        numbers = {x: 0 for x in range(len(action_classes))}  #####\n",
    "        ##################################################################\n",
    "        for file in working_files_with_labels:\n",
    "            frames_blocks, label = create_coords_blocks(file)\n",
    "            if label != [] and numbers[label[0]] <= 150:\n",
    "                numbers[label[0]] = numbers[label[0]] + len(label)\n",
    "                data = data + frames_blocks\n",
    "                labels = labels + label\n",
    "        data_np = np.asarray(data)\n",
    "        labels_np = np.asarray(labels)\n",
    "\n",
    "        data_sq = data_np.reshape(len(data_np), -1)\n",
    "        data = pd.DataFrame(data_sq)\n",
    "        labels = pd.DataFrame(labels_np)\n",
    "        data['labels'] = labels\n",
    "        \n",
    "\n",
    "        self.data = data\n",
    "        self.labels = data['labels'].astype('float32')\n",
    "        self.transform = transform\n",
    "        \n",
    "           \n",
    "    def __len__(self):\n",
    "         return len(self.data)\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        item = np.asarray(self.data.iloc[idx,:-1]).reshape(45,75)\n",
    "        label = self.labels[idx]\n",
    "        if self.transform != None:\n",
    "            item = transform(item)\n",
    "        return (item, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action classes:  {10: 0, 27: 1, 55: 2, 8: 3, 2: 4, 23: 5, 22: 6, 7: 7, 21: 8}\n",
      "action files:  {10: 120, 27: 120, 55: 120, 8: 120, 2: 120, 23: 120, 22: 120, 7: 120, 21: 120}\n"
     ]
    }
   ],
   "source": [
    "dataset = Skeleton_Dataset(data_path=data_path, broken_files_path=broken_files_path, \n",
    "                           training_classes=training_classes,num_joint = 25, \n",
    "                           max_frame = 300, transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [int(0.75*len(dataset)),\n",
    "                                                                      len(dataset) - int(0.75*len(dataset))])\n",
    "train_loader = DataLoader(train_dataset, batch_size = 16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size = 1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_net(nn.Module):\n",
    "    def __init__(self,input_dim,hidden_dim,output_dim,layer_num):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.lstm = torch.nn.LSTM(input_dim, hidden_dim,layer_num,batch_first=True)\n",
    "        self.dr = torch.nn.Dropout2d(0.1)\n",
    "        self.fc = torch.nn.Linear(hidden_dim,output_dim)\n",
    "        \n",
    "        \n",
    "    def forward(self,inputs):\n",
    "        x = inputs\n",
    "        lstm_out,(hn,cn) = self.lstm(x)\n",
    "        out = self.fc(lstm_out[:,-1,:])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM_net(\n",
       "  (lstm): LSTM(75, 128, num_layers=2, batch_first=True)\n",
       "  (dr): Dropout2d(p=0.1, inplace=False)\n",
       "  (fc): Linear(in_features=128, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_hidden = 128\n",
    "n_joints = 25*3\n",
    "n_categories = len(LABELS)\n",
    "n_layer = 2\n",
    "rnn = LSTM_net(n_joints,n_hidden,n_categories,n_layer)\n",
    "rnn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categoryFromOutput(output):\n",
    "    top_n, top_i = output.topk(1)\n",
    "    category_i = top_i[0].item()\n",
    "#     print(output.topk(5))\n",
    "    return LABELS[category_i], category_i\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 iter : 0 (0m 0s) 2.1945  / 27 ✓\n",
      "epoch : 9 iter : 5 (1m 49s) 2.2103  / 10 ✗ (8)\n",
      "epoch : 18 iter : 10 (3m 40s) 2.1837  / 10 ✗ (2)\n",
      "epoch : 27 iter : 15 (5m 33s) 2.1119  / 23 ✓\n",
      "epoch : 36 iter : 20 (7m 23s) 2.0063  / 23 ✓\n",
      "epoch : 45 iter : 25 (9m 18s) 1.9265  / 23 ✗ (27)\n",
      "epoch : 54 iter : 30 (11m 13s) 2.0999  / 10 ✓\n",
      "epoch : 63 iter : 35 (13m 1s) 1.7146  / 23 ✓\n",
      "epoch : 72 iter : 40 (14m 52s) 1.5551  / 21 ✓\n",
      "epoch : 81 iter : 45 (16m 43s) 1.7394  / 2 ✗ (22)\n",
      "epoch : 90 iter : 50 (18m 29s) 1.4394  / 7 ✗ (8)\n",
      "epoch : 100 iter : 0 (20m 14s) 1.5019  / 21 ✗ (27)\n",
      "epoch : 109 iter : 5 (22m 5s) 1.6171  / 22 ✓\n",
      "epoch : 118 iter : 10 (23m 56s) 1.5789  / 7 ✗ (2)\n",
      "epoch : 127 iter : 15 (25m 51s) 1.2610  / 2 ✗ (22)\n",
      "epoch : 136 iter : 20 (27m 47s) 0.8872  / 7 ✓\n",
      "epoch : 145 iter : 25 (29m 40s) 0.8922  / 10 ✓\n",
      "epoch : 154 iter : 30 (31m 26s) 1.5808  / 21 ✓\n",
      "epoch : 163 iter : 35 (33m 19s) 1.2158  / 10 ✗ (21)\n",
      "epoch : 172 iter : 40 (35m 13s) 1.5505  / 23 ✓\n",
      "epoch : 181 iter : 45 (37m 9s) 1.6344  / 21 ✓\n",
      "epoch : 190 iter : 50 (39m 3s) 1.3998  / 21 ✗ (2)\n",
      "epoch : 200 iter : 0 (40m 57s) 1.0764  / 22 ✓\n",
      "epoch : 209 iter : 5 (42m 49s) 1.3923  / 27 ✓\n",
      "epoch : 218 iter : 10 (44m 36s) 1.2599  / 21 ✗ (2)\n",
      "epoch : 227 iter : 15 (46m 31s) 0.8242  / 55 ✓\n",
      "epoch : 236 iter : 20 (48m 25s) 0.9952  / 23 ✗ (22)\n",
      "epoch : 245 iter : 25 (50m 15s) 1.0167  / 10 ✓\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.0007\n",
    "optimizer = optim.SGD(rnn.parameters(),lr=learning_rate,momentum=0.9)\n",
    "\n",
    "all_losses = []\n",
    "start = time.time()\n",
    "counter = 0\n",
    "for epoch in range(250):  \n",
    "    current_loss = 0\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        \n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        output = rnn(inputs.float())\n",
    "        labels = labels.type(torch.LongTensor).to(device)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "\n",
    "\n",
    "        current_loss += loss.item()\n",
    "        category = LABELS[int(labels[0])]\n",
    "\n",
    "        if counter % 500 == 0:\n",
    "            guess, guess_i = categoryFromOutput(output)\n",
    "            correct = '✓' if guess == category else '✗ (%s)' % category\n",
    "            print('epoch : %d iter : %d (%s) %.4f  / %s %s' % (epoch, i, timeSince(start), loss, guess, correct))\n",
    "\n",
    "        \n",
    "        counter = counter + 1\n",
    "    if counter % 100 == 0:\n",
    "        all_losses.append(current_loss / 25)\n",
    "        current_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network:   45.205479452054796\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "right = 0\n",
    "counter = 0\n",
    "\n",
    "rnn.eval()\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_loader, 0):\n",
    "        counter = counter + 1\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)  \n",
    "        output = rnn(inputs.float())\n",
    "        guess, guess_i = categoryFromOutput(output)\n",
    "        category = LABELS[int(labels[0])]\n",
    "        \n",
    "        if guess == category:\n",
    "            right = right + 1\n",
    "\n",
    "\n",
    "print('Accuracy of the network:  ',  (100 * right / counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM_net(\n",
       "  (lstm): LSTM(75, 384, num_layers=2, batch_first=True)\n",
       "  (dr): Dropout2d(p=0.1, inplace=False)\n",
       "  (fc): Linear(in_features=384, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_hidden = 128*3\n",
    "n_joints = 25*3\n",
    "n_categories = len(LABELS)\n",
    "n_layer = 2\n",
    "rnn = LSTM_net(n_joints,n_hidden,n_categories,n_layer)\n",
    "rnn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_net(nn.Module):\n",
    "    def __init__(self,input_dim,hidden_dim,output_dim,layer_num):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.lstm = torch.nn.LSTM(input_dim, hidden_dim,layer_num,batch_first=True)\n",
    "        self.dr = torch.nn.Dropout2d(0.1)\n",
    "        self.fc = torch.nn.Linear(hidden_dim,output_dim)\n",
    "        \n",
    "        \n",
    "    def forward(self,inputs):\n",
    "        x = inputs\n",
    "        lstm_out,(hn,cn) = self.lstm(x)\n",
    "        out = self.fc(lstm_out[:,-1,:])\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 iter : 0 (0m 0s) 2.1959  / 21 ✗ (8)\n",
      "epoch : 9 iter : 5 (1m 0s) 2.1635  / 10 ✗ (2)\n",
      "epoch : 18 iter : 10 (1m 57s) 2.1943  / 10 ✗ (8)\n",
      "epoch : 27 iter : 15 (2m 56s) 2.1457  / 23 ✗ (27)\n",
      "epoch : 36 iter : 20 (3m 53s) 1.8627  / 23 ✓\n",
      "epoch : 45 iter : 25 (4m 59s) 1.8783  / 21 ✗ (7)\n",
      "epoch : 54 iter : 30 (6m 7s) 1.4062  / 10 ✗ (8)\n",
      "epoch : 63 iter : 35 (7m 7s) 1.5918  / 2 ✗ (55)\n",
      "epoch : 72 iter : 40 (8m 6s) 1.3491  / 22 ✗ (55)\n",
      "epoch : 81 iter : 45 (9m 5s) 1.6471  / 23 ✓\n",
      "epoch : 90 iter : 50 (10m 4s) 1.7037  / 2 ✗ (22)\n",
      "epoch : 100 iter : 0 (11m 2s) 1.1231  / 21 ✗ (7)\n",
      "epoch : 109 iter : 5 (12m 0s) 1.6700  / 8 ✓\n",
      "epoch : 118 iter : 10 (12m 59s) 1.1781  / 23 ✓\n",
      "epoch : 127 iter : 15 (13m 57s) 1.1609  / 8 ✗ (2)\n",
      "epoch : 136 iter : 20 (14m 56s) 1.7309  / 2 ✗ (8)\n",
      "epoch : 145 iter : 25 (15m 54s) 0.7089  / 2 ✓\n",
      "epoch : 154 iter : 30 (16m 53s) 1.1550  / 23 ✓\n",
      "epoch : 163 iter : 35 (17m 51s) 1.2088  / 8 ✓\n",
      "epoch : 172 iter : 40 (18m 50s) 1.3659  / 22 ✗ (21)\n",
      "epoch : 181 iter : 45 (19m 48s) 1.0940  / 23 ✓\n",
      "epoch : 190 iter : 50 (20m 47s) 0.9609  / 21 ✗ (7)\n",
      "epoch : 200 iter : 0 (21m 46s) 0.4541  / 8 ✓\n",
      "epoch : 209 iter : 5 (22m 45s) 0.5822  / 2 ✓\n",
      "epoch : 218 iter : 10 (23m 43s) 0.7849  / 21 ✗ (55)\n",
      "epoch : 227 iter : 15 (24m 42s) 1.0375  / 2 ✓\n",
      "epoch : 236 iter : 20 (25m 41s) 1.1777  / 2 ✓\n",
      "epoch : 245 iter : 25 (26m 39s) 0.7570  / 21 ✓\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.0007\n",
    "optimizer = optim.SGD(rnn.parameters(),lr=learning_rate,momentum=0.9)\n",
    "\n",
    "all_losses = []\n",
    "start = time.time()\n",
    "counter = 0\n",
    "for epoch in range(250):  \n",
    "    current_loss = 0\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        \n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        output = rnn(inputs.float())\n",
    "        labels = labels.type(torch.LongTensor).to(device)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "\n",
    "\n",
    "        current_loss += loss.item()\n",
    "        category = LABELS[int(labels[0])]\n",
    "\n",
    "        if counter % 500 == 0:\n",
    "            guess, guess_i = categoryFromOutput(output)\n",
    "            correct = '✓' if guess == category else '✗ (%s)' % category\n",
    "            print('epoch : %d iter : %d (%s) %.4f  / %s %s' % (epoch, i, timeSince(start), loss, guess, correct))\n",
    "\n",
    "        \n",
    "        counter = counter + 1\n",
    "    if counter % 100 == 0:\n",
    "        all_losses.append(current_loss / 25)\n",
    "        current_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network:   59.24657534246575\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "right = 0\n",
    "counter = 0\n",
    "\n",
    "rnn.eval()\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_loader, 0):\n",
    "        counter = counter + 1\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)  \n",
    "        output = rnn(inputs.float())\n",
    "        guess, guess_i = categoryFromOutput(output)\n",
    "        category = LABELS[int(labels[0])]\n",
    "        \n",
    "        if guess == category:\n",
    "            right = right + 1\n",
    "\n",
    "\n",
    "print('Accuracy of the network:  ',  (100 * right / counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_classes = sorted([8, 10, 22, 23, 27, 21, 55, 2, 7]) #классы которые будем использовать для обучения, полный список прдставлен тут https://github.com/shahroudy/NTURGB-D\n",
    "LABELS = {x: training_classes[x] for x in range(len(training_classes))}\n",
    "training_cameras = [1, 2, 3] \n",
    "\n",
    "\n",
    "num_joint = 25\n",
    "max_frame = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action classes:  {10: 0, 27: 1, 55: 2, 8: 3, 2: 4, 23: 5, 22: 6, 7: 7, 21: 8}\n",
      "action files:  {10: 120, 27: 120, 55: 120, 8: 120, 2: 120, 23: 120, 22: 120, 7: 120, 21: 120}\n"
     ]
    }
   ],
   "source": [
    "dataset = Skeleton_Dataset(data_path=data_path, broken_files_path=broken_files_path, \n",
    "                           training_classes=training_classes,num_joint = num_joint, \n",
    "                           max_frame = max_frame, transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM_net(\n",
       "  (lstm): LSTM(75, 384, num_layers=2, batch_first=True)\n",
       "  (dr): Dropout2d(p=0.1, inplace=False)\n",
       "  (fc): Linear(in_features=384, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_hidden = 128*3\n",
    "n_joints = 25*3\n",
    "n_categories = len(LABELS)\n",
    "n_layer = 2\n",
    "rnn = LSTM_net(n_joints,n_hidden,n_categories,n_layer)\n",
    "rnn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 iter : 0 (0m 0s) 2.1997  / 27 ✓\n",
      "epoch : 9 iter : 5 (1m 3s) 2.2343  / 10 ✗ (2)\n",
      "epoch : 18 iter : 10 (2m 2s) 2.1974  / 10 ✗ (8)\n",
      "epoch : 27 iter : 15 (3m 1s) 2.0792  / 10 ✗ (55)\n",
      "epoch : 36 iter : 20 (4m 0s) 1.8060  / 21 ✗ (55)\n",
      "epoch : 45 iter : 25 (4m 58s) 1.7076  / 21 ✗ (22)\n",
      "epoch : 54 iter : 30 (5m 57s) 2.3444  / 10 ✗ (27)\n",
      "epoch : 63 iter : 35 (6m 56s) 1.9741  / 2 ✗ (7)\n",
      "epoch : 72 iter : 40 (7m 54s) 1.5439  / 22 ✓\n",
      "epoch : 81 iter : 45 (8m 53s) 1.4507  / 21 ✗ (8)\n",
      "epoch : 90 iter : 50 (9m 52s) 1.4633  / 22 ✗ (23)\n",
      "epoch : 100 iter : 0 (10m 51s) 1.7222  / 2 ✓\n",
      "epoch : 109 iter : 5 (11m 50s) 1.7205  / 21 ✗ (55)\n",
      "epoch : 118 iter : 10 (12m 48s) 1.2955  / 2 ✓\n",
      "epoch : 127 iter : 15 (13m 48s) 1.1215  / 10 ✓\n",
      "epoch : 136 iter : 20 (14m 51s) 1.5828  / 21 ✗ (22)\n",
      "epoch : 145 iter : 25 (15m 49s) 1.3729  / 27 ✓\n",
      "epoch : 154 iter : 30 (16m 46s) 1.3438  / 21 ✗ (55)\n",
      "epoch : 163 iter : 35 (17m 44s) 1.1932  / 2 ✗ (22)\n",
      "epoch : 172 iter : 40 (18m 42s) 0.7531  / 7 ✓\n",
      "epoch : 181 iter : 45 (19m 40s) 1.3227  / 21 ✓\n",
      "epoch : 190 iter : 50 (20m 39s) 0.8513  / 8 ✓\n",
      "epoch : 200 iter : 0 (21m 45s) 0.7029  / 55 ✗ (22)\n",
      "epoch : 209 iter : 5 (23m 1s) 0.9965  / 22 ✓\n",
      "epoch : 218 iter : 10 (24m 2s) 0.4401  / 27 ✗ (55)\n",
      "epoch : 227 iter : 15 (25m 1s) 0.6020  / 2 ✗ (55)\n",
      "epoch : 236 iter : 20 (26m 0s) 0.7721  / 7 ✓\n",
      "epoch : 245 iter : 25 (26m 59s) 0.3735  / 22 ✓\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.0007\n",
    "optimizer = optim.SGD(rnn.parameters(),lr=learning_rate,momentum=0.9)\n",
    "\n",
    "all_losses = []\n",
    "start = time.time()\n",
    "counter = 0\n",
    "for epoch in range(250):  \n",
    "    current_loss = 0\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        \n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        output = rnn(inputs.float())\n",
    "        labels = labels.type(torch.LongTensor).to(device)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "\n",
    "\n",
    "        current_loss += loss.item()\n",
    "        category = LABELS[int(labels[0])]\n",
    "\n",
    "        if counter % 500 == 0:\n",
    "            guess, guess_i = categoryFromOutput(output)\n",
    "            correct = '✓' if guess == category else '✗ (%s)' % category\n",
    "            print('epoch : %d iter : %d (%s) %.4f  / %s %s' % (epoch, i, timeSince(start), loss, guess, correct))\n",
    "\n",
    "        \n",
    "        counter = counter + 1\n",
    "    if counter % 100 == 0:\n",
    "        all_losses.append(current_loss / 25)\n",
    "        current_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network:   53.42465753424658\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "right = 0\n",
    "counter = 0\n",
    "\n",
    "rnn.eval()\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_loader, 0):\n",
    "        counter = counter + 1\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)  \n",
    "        output = rnn(inputs.float())\n",
    "        guess, guess_i = categoryFromOutput(output)\n",
    "        category = LABELS[int(labels[0])]\n",
    "        \n",
    "        if guess == category:\n",
    "            right = right + 1\n",
    "\n",
    "\n",
    "print('Accuracy of the network:  ',  (100 * right / counter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Увеличение n_hidden повысило точность модели. Но уменьшение кадров понизило точность."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
